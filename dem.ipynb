{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting stemming\n",
      "  Using cached stemming-1.0.1.zip (13 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: stemming\n",
      "  Building wheel for stemming (setup.py): started\n",
      "  Building wheel for stemming (setup.py): finished with status 'done'\n",
      "  Created wheel for stemming: filename=stemming-1.0.1-py3-none-any.whl size=11144 sha256=4116a5bd4e57eb3f32d75960339122e36ab5239103395f4ac82c3eddac0902f2\n",
      "  Stored in directory: c:\\users\\comp\\appdata\\local\\pip\\cache\\wheels\\dd\\7f\\72\\4b4f6342d6be71f40e869fdb0e406c051a390e1507e0380ecb\n",
      "Successfully built stemming\n",
      "Installing collected packages: stemming\n",
      "Successfully installed stemming-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\COMP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "# stemmer remove words\n",
    "# lemintaniation tokenization use \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['e', 'he', 'Lancaster', 'Stemmer', 'is', 'designed', 'for', 'speed', ',', 'making', 'it', 'suitable', 'for', 'processing', 'large', '.']\n",
      "Stemmed words: ['e', 'he', 'Lancast', 'Stem', '', 'design', 'for', 'spee', ',', 'mak', 'it', 'suit', 'for', '', 'larg', '.']\n"
     ]
    }
   ],
   "source": [
    "from stemming.paicehusk import stem\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"e he Lancaster Stemmer is designed for speed, making it suitable for processing large.\"\n",
    "words = word_tokenize(text)\n",
    "\n",
    "stemmed_words = [stem(word) for word in words]\n",
    "\n",
    "print(\"Original words:\", words)\n",
    "print(\"Stemmed words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the different types of the stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porter,snowball,regex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['Comment', 'ça', 'vaeme', '?']\n",
      "Stemmed words: ['comment', 'ça', 'vaem', '?']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "# Porter stemming for the remove the words them use t\n",
    "# can steam only the englisht language \n",
    "porter_stemmer = PorterStemmer()\n",
    "# words = [\"running \", \"care\", \"jumps\", \"happily\", \"programming\"]\n",
    "# Wie geht es dir \n",
    "\n",
    "# words = [\"Wie\", \"gehte\", \"es\", \"dir\"]\n",
    "words = [\"Comment\",\"ça\",\"vaeme\",\"?\"]\n",
    "\n",
    "stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
    "print(\"Original words:\", words)\n",
    "print(\"Stemmed words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment ----> comment\n",
      "ça ----> ça\n",
      "vaeme ----> vaem\n",
      "? ----> ?\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "#t the stemmer snowball stemmer\n",
    "# can stem the different language\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "# words = ['cared','university','fairly','easily','singing',\n",
    "# \t 'sings','sung','singer','sportingly']\n",
    "\n",
    "words = [\"Comment\",\"ça\",\"vaeme\",\"?\"]\n",
    "\n",
    "stem_words = []\n",
    "for w in words:\n",
    "\tx = snow_stemmer.stem(w)\n",
    "\tstem_words.append(x)\n",
    "\t\n",
    "for e1,e2 in zip(words,stem_words):\n",
    "\tprint(e1+' ----> '+e2)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['manges', 'marchent', 'men', 'rapidement', 'libération', 'magnifique', 'amoureux']\n",
      "Stemmed words: ['mang', 'march', 'm', 'rapidem', 'libér', 'magnifiqu', 'amour']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to apply regex-based stemming\n",
    "def regex_stemmer(word):\n",
    "    # Define common French suffixes to remove\n",
    "    suffixes = [\n",
    "        r\"(en|e|es|ent|ant)$\",   # Plural forms or participles\n",
    "        r\"(ment|ement)$\",     # Adverbs\n",
    "        r\"(ation|ition|ution)$\", # Nouns ending with -ation, -ition, -ution\n",
    "        r\"(ique|able|ible)$\", # Adjectives\n",
    "        r\"(eux|euse)$\",       # Adjectives (masculine/feminine)\n",
    "        r\"(s|x)$\"             # General plural forms\n",
    "    ]\n",
    "    \n",
    "    for suffix in suffixes:\n",
    "        word = re.sub(suffix, \"\", word)  # Remove the suffix if it matches\n",
    "    return word\n",
    "\n",
    "# List of French words to test\n",
    "words = [\"manges\", \"marchent\",\"men\",\"rapidement\", \"libération\", \"magnifique\", \"amoureux\"]\n",
    "\n",
    "# Apply the regex stemmer\n",
    "stemmed_words = [regex_stemmer(word) for word in words]\n",
    "\n",
    "# for word in words:\n",
    "#     regex_stemmer(word)\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Original words:\", words)\n",
    "print(\"Stemmed words:\", stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
